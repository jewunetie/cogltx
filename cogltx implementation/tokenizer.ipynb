{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Pacific Economic Cooperation Council (PECC) has issued a report examining the economic impact of the COVID-19 crisis on the Asia-Pacific region and outlining an agenda for cooperation.The technical and policy-focused publication titled, ‘State of the Region: Special report on COVID-19,’ acknowledges high levels of policy uncertainty in the region due to the pandemic, as well as the scale and duration of related economic and social shocks, and pace of recovery. The report thus focuses on how regional cooperation can provide governments with more options for recovery in the face of these uncertainties.The report collates a set of proposals using data collected from 710 survey respondents in business, academia, government, and civil society between 9 May and 12 June 2020. The results show greater levels of pessimism on economic impacts to the region than official estimates indicate. The report points to regional stimulus efforts totaling approximately USD 5.4 trillion, and notes that while policymakers’ appetites are constrained by memories of recent financial crises, “regional economies have space for further stimulus.”Regional mechanisms, the authors emphasize, can facilitate the design and implementation of coordination and cooperation packages, and build a sense of direction to support future growth. They note that top priorities for regional cooperation include sharing pandemic preparedness practices, vaccine development, and three aspects of trade with respect to essential products: the facilitation of trade as a whole; the removal of export restrictions; and the removal of tariffs.Observing that the pandemic has both deepened and accelerated preexisting trends, the report notes the importance of human contact, but also opportunities around digital technology and the multitude of connections available. As schools remain shuttered in many parts of the world, the report notes remote learning opportunities, with the caveat that risks remain around the digital divide despite action being taken through the Asia-Pacific Economic Cooperation (APEC) Internet and Digital Roadmap.To address the “first order” priorities stemming from the pandemic, the report recommends multilateral actions that facilitate regional progress on seven issue areas:Information sharing;Flow of essential products;Moving beyond gross domestic product (GDP);Facilitating e-commerce;Restarting travel;Minimizing disruption to supply chains; andContact tracing.A message from PECC co-chairs Don Campbell and Su Ge highlights that this year marks PECC’s 40th anniversary and that the rationale behind the Council’s establishment still rings true today. They note that “[w]e can only resolve this pandemic and economic crisis through effective cooperation.” [Publication:State of the Region Report: Impact of the Covid‐19 Crisis] [Publication Landing Page]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Pacific Economic Cooperation Council (PECC) has issued a report examining the economic impact of the COVID-19 crisis on the Asia-Pacific region and outlining an agenda for cooperation.The technical and policy-focused publication titled, ‘State of the Region: Special report on COVID-19,’ acknowledges\\xa0high levels of policy uncertainty in the region due to the pandemic,\\xa0as well as the scale and duration of related economic and social shocks, and pace of recovery. The report thus focuses on how regional cooperation can provide governments with more options for recovery in the face of these uncertainties.The report collates a set of proposals using data collected from 710 survey respondents in business, academia, government, and civil society between 9 May and 12 June 2020. The results show greater levels of pessimism on economic impacts to the region than official estimates indicate. The report points to regional stimulus efforts totaling approximately USD 5.4 trillion, and notes that while policymakers’ appetites are constrained by memories of recent financial crises, “regional economies have space for further stimulus.”Regional mechanisms, the\\xa0authors emphasize, can facilitate the design and implementation of coordination and cooperation packages, and build a sense of direction to support future growth. They note that top priorities for regional cooperation include sharing pandemic preparedness practices, vaccine development, and three aspects of trade with respect to essential products: the facilitation of trade as a whole; the removal of export restrictions; and the removal of tariffs.Observing that the pandemic has both deepened and accelerated preexisting trends, the report notes the importance of human contact, but also opportunities around digital technology and the multitude of connections available. As schools remain shuttered in many parts of the world, the report notes remote learning opportunities, with the caveat that risks remain around the digital divide despite action being taken through the Asia-Pacific Economic Cooperation (APEC) Internet and Digital Roadmap.To address the “first order” priorities stemming from the pandemic, the report recommends multilateral actions that facilitate regional progress on seven issue areas:Information sharing;Flow of essential products;Moving beyond gross domestic product (GDP);Facilitating e-commerce;Restarting travel;Minimizing disruption to supply chains; andContact tracing.A message from PECC co-chairs Don Campbell and Su Ge highlights that this year marks PECC’s 40th\\xa0anniversary and that the rationale behind the Council’s establishment still rings true today. They note that “[w]e can only resolve this pandemic and economic crisis through effective cooperation.” [Publication:State of the Region Report: Impact of the Covid‐19 Crisis] [Publication Landing Page]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "class SentenceProcessor():\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "        self.CLS_TOKEN = self.tokenizer.cls_token_id\n",
    "        self.PAD_TOKEN = self.tokenizer.pad_token_id\n",
    "        self.SEP_TOKEN = self.tokenizer.sep_token_id\n",
    "        \n",
    "        self.num_prev_sentences = 2\n",
    "        self.max_block_size = 510\n",
    "        \n",
    "    def preprocess(self, text):\n",
    "        # clean the text by removing unnecessary characters\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        # split text into sentences\n",
    "        sentences = nltk.tokenize.sent_tokenize(text)\n",
    "        \n",
    "        # convert sentences into tokens\n",
    "        sentences_ids = [self.tokenizer.encode_plus(\n",
    "                                    sentence, \n",
    "                                    add_special_tokens=False, \n",
    "                                    padding=False, \n",
    "                                    truncation=False,\n",
    "                                    return_token_type_ids=False,\n",
    "                                    return_attention_mask=False,\n",
    "                                    return_tensors='pt',\n",
    "                                    verbose=False)['input_ids'].tolist()[0] for sentence in sentences]\n",
    "        \n",
    "        ### split tokens into blocks of 512 tokens ###\n",
    "        \n",
    "        input_ids_blocks = []\n",
    "        attention_blocks = []\n",
    "        \n",
    "        def add_to_input_ids_blocks(input_ids):\n",
    "            assert len(input_ids) <= self.max_block_size\n",
    "            \n",
    "            pad_len = self.max_block_size - len(input_ids)\n",
    "            \n",
    "            input_ids.insert(0, self.CLS_TOKEN)\n",
    "            input_ids.append(self.SEP_TOKEN)\n",
    "            \n",
    "            attention_mask = [1] * len(input_ids)\n",
    "            \n",
    "            # add padding length to make all the blocks the same size\n",
    "            if pad_len > 0:\n",
    "                input_ids.extend([self.PAD_TOKEN] * pad_len)\n",
    "                attention_mask.extend([0] * pad_len)\n",
    "            \n",
    "            input_ids_blocks.append(input_ids)\n",
    "            attention_blocks.append(attention_mask)\n",
    "        \n",
    "        \n",
    "        current_input_ids = []\n",
    "        for i, sentence_ids in enumerate(sentences_ids):\n",
    "            if (len(current_input_ids) + len(sentence_ids) <= self.max_block_size):\n",
    "                # if current block has enough space for the current sentence\n",
    "                current_input_ids.extend(sentence_ids)\n",
    "            else:\n",
    "                # if the current block doesn't have enough space for the current sentence\n",
    "                \n",
    "                # clear the current block\n",
    "                if current_input_ids:\n",
    "                    add_to_input_ids_blocks(current_input_ids)\n",
    "                    current_input_ids = []\n",
    "                \n",
    "                # if the sentence is too long to be less than max token size, trucate it\n",
    "                if not (len(sentence_ids) <= self.max_block_size):\n",
    "                    current_input_ids = sentence_ids[:self.max_block_size]\n",
    "                    add_to_input_ids_blocks(current_input_ids)\n",
    "                    current_input_ids = []\n",
    "                    continue\n",
    "                \n",
    "                current_input_ids.extend(sentence_ids)\n",
    "                \n",
    "                # add the previous sentences to the current block if it is less than 512 tokens\n",
    "                for j in range(min(self.num_prev_sentences, i)):\n",
    "                    prev_sentence = sentences_ids[i-j-1]\n",
    "                    if len(current_input_ids) + len(prev_sentence) <= self.max_block_size:\n",
    "                        current_input_ids[:0] = prev_sentence\n",
    "                    else:\n",
    "                        # retain some of the first previous sentence for context learning\n",
    "                        if j == 0:\n",
    "                            diff = self.max_block_size - len(current_input_ids)\n",
    "                            current_input_ids[:0] = prev_sentence[len(prev_sentence) - diff:len(prev_sentence)]\n",
    "                            add_to_input_ids_blocks(current_input_ids)\n",
    "                            current_input_ids = []\n",
    "                        break\n",
    "            \n",
    "            if i == len(sentences_ids) - 1 and current_input_ids:\n",
    "                add_to_input_ids_blocks(current_input_ids)\n",
    "                current_input_ids = []\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.IntTensor(input_ids_blocks),\n",
    "            'attention_mask': torch.IntTensor(attention_blocks)\n",
    "        }\n",
    "        \n",
    "    \n",
    "sprocessor = SentenceProcessor()\n",
    "print(sprocessor.preprocess(text)['input_ids'].shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
